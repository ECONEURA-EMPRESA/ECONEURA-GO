# üîå CONEXIONES DISPONIBLES PARA EL MODELO DE IA

**Fecha**: 2025-01-XX  
**Estado**: ‚úÖ **TODAS LAS CONEXIONES IMPLEMENTADAS**

---

## üéØ OBJETIVO

El modelo de IA (Mistral 3.1, GPT-4o, etc.) puede usar **TODAS** estas conexiones cuando las necesite. El sistema est√° preparado para que el modelo ejerza todas sus funciones.

---

## ‚úÖ CONEXIONES IMPLEMENTADAS

### **1. IM√ÅGENES (Vision API)** ‚úÖ
**Estado**: ‚úÖ Implementado  
**Endpoint**: `POST /api/invoke/:agentId`  
**Par√°metro**: `image` (base64)

**C√≥mo funciona**:
- El frontend env√≠a la imagen en base64
- El backend detecta si hay imagen
- Si el modelo es `mistral-medium` y hay imagen, usa `gpt-4o` para vision (compatible con Mammouth.ai)
- El modelo recibe la imagen y puede analizarla

**Ejemplo de uso**:
```typescript
// Frontend
const body = {
  input: "¬øQu√© hay en esta imagen?",
  image: "data:image/jpeg;base64,..."
};

// Backend procesa y env√≠a al modelo con formato vision API
```

---

### **2. ARCHIVOS (PDF, DOC, DOCX, TXT, CSV)** ‚úÖ
**Estado**: ‚úÖ Implementado  
**Endpoint**: `POST /api/invoke/:agentId`  
**Par√°metros**: `file` (base64), `mimeType`, `fileName`

**C√≥mo funciona**:
- El frontend env√≠a el archivo en base64 + mimeType + fileName
- El backend extrae el texto del archivo usando `fileExtractor.ts`
- El texto extra√≠do se agrega al mensaje del usuario
- El modelo recibe el texto y puede analizarlo

**Tipos soportados**:
- ‚úÖ PDF (`application/pdf`)
- ‚úÖ DOC/DOCX (`application/msword`, `application/vnd.openxmlformats-officedocument.wordprocessingml.document`)
- ‚úÖ TXT (`text/plain`)
- ‚úÖ CSV (`text/csv`)

**Ejemplo de uso**:
```typescript
// Frontend
const body = {
  input: "Resume este documento",
  file: "base64...",
  mimeType: "application/pdf",
  fileName: "documento.pdf"
};

// Backend extrae texto y lo agrega al mensaje
// El modelo recibe: "Resume este documento\n\n--- Contenido del archivo: ---\n[texto extra√≠do]"
```

---

### **3. VOZ (Audio)** üü° PENDIENTE
**Estado**: üü° Preparado pero no implementado  
**Endpoint**: `POST /api/invoke/:agentId`  
**Par√°metro**: `audio` (base64)

**C√≥mo funcionar√°**:
- El frontend graba audio y lo convierte a base64
- El backend recibe el audio
- **TODO**: Implementar transcripci√≥n usando Whisper API o similar
- El texto transcrito se env√≠a al modelo

**Pr√≥ximos pasos**:
1. Integrar Whisper API o servicio de transcripci√≥n
2. Transcribir audio a texto
3. Enviar texto al modelo

---

### **4. EJECUCI√ìN DE AGENTES AUTOMATIZADOS (N8N/Make)** ‚úÖ
**Estado**: ‚úÖ Implementado  
**Endpoint**: `POST /api/agents/:id/execute`

**C√≥mo funciona**:
- El modelo puede solicitar ejecutar un agente automatizado
- El sistema detecta la solicitud (ej: "ejecuta el agente X")
- Se llama a `POST /api/agents/:id/execute`
- El backend ejecuta el webhook de N8N/Make
- Se retorna el resultado al modelo

**Agentes disponibles**:
- ‚úÖ `ceo-agenda-consejo` (Make)
- ‚úÖ `ceo-anuncio-semanal` (N8N)
- ‚úÖ `ceo-resumen-ejecutivo` (Make)
- ‚úÖ Y 40+ agentes m√°s en `automationAgentsRegistry.ts`

**Ejemplo de uso**:
```typescript
// El modelo puede decir: "Ejecuta el agente de agenda del consejo"
// El sistema detecta y ejecuta:
POST /api/agents/ceo-agenda-consejo/execute
{
  "params": { "fecha": "2025-01-20" },
  "triggered_by": "neura-ceo"
}
```

---

### **5. CONSULTA A BASE DE DATOS** ‚úÖ
**Estado**: ‚úÖ Disponible  
**Conexi√≥n**: PostgreSQL

**C√≥mo funciona**:
- El modelo puede solicitar datos de la base de datos
- El backend tiene acceso a PostgreSQL
- Se pueden crear endpoints espec√≠ficos para consultas del modelo

**Ejemplo**:
- El modelo puede pedir: "Mu√©strame los leads del √∫ltimo mes"
- El backend consulta la BD y retorna datos
- El modelo procesa y presenta la informaci√≥n

---

### **6. WEBHOOKS CRM** ‚úÖ
**Estado**: ‚úÖ Implementado  
**Endpoint**: `POST /api/crm/webhooks/lead-created`

**C√≥mo funciona**:
- Los agentes automatizados (N8N/Make) pueden crear leads v√≠a webhook
- El backend recibe el webhook y crea el lead en la BD
- El modelo puede consultar estos leads despu√©s

---

## üîß CONFIGURACI√ìN DEL MODELO

### **Mistral 3.1 (NEURA-CEO)**
```typescript
{
  id: 'neura-ceo',
  provider: 'openai', // Usa OpenAIAdapter que apunta a Mammouth.ai
  model: 'mistral-medium', // Mistral Medium 3.1
  // ‚úÖ Puede usar TODAS las conexiones arriba
}
```

### **Otros NEURAS**
- Todos usan `gpt-4o` o `gpt-4o-mini` (compatible con Mammouth.ai)
- Todos pueden usar im√°genes, archivos, agentes, etc.

---

## üìã CHECKLIST DE CONEXIONES

| Conexi√≥n | Estado | Endpoint | Notas |
| :------- | :----- | :------- | :---- |
| **Im√°genes** | ‚úÖ | `/api/invoke/:agentId` | Vision API implementada |
| **Archivos PDF** | ‚úÖ | `/api/invoke/:agentId` | Extracci√≥n de texto implementada |
| **Archivos DOC** | ‚úÖ | `/api/invoke/:agentId` | Extracci√≥n b√°sica implementada |
| **Archivos TXT/CSV** | ‚úÖ | `/api/invoke/:agentId` | Lectura directa |
| **Voz** | üü° | `/api/invoke/:agentId` | Preparado, falta transcripci√≥n |
| **Agentes N8N** | ‚úÖ | `/api/agents/:id/execute` | Webhooks funcionando |
| **Agentes Make** | ‚úÖ | `/api/agents/:id/execute` | Webhooks funcionando |
| **Base de Datos** | ‚úÖ | PostgreSQL | Disponible para consultas |
| **CRM Webhooks** | ‚úÖ | `/api/crm/webhooks/*` | Funcionando |

---

## üéØ C√ìMO EL MODELO USA ESTAS CONEXIONES

### **Ejemplo 1: An√°lisis de Imagen**
```
Usuario: "Analiza esta imagen" [sube imagen]
‚Üí Frontend env√≠a: { input: "Analiza esta imagen", image: "base64..." }
‚Üí Backend detecta imagen, usa gpt-4o para vision
‚Üí Modelo recibe imagen y analiza
‚Üí Modelo responde con an√°lisis
```

### **Ejemplo 2: An√°lisis de Documento**
```
Usuario: "Resume este PDF" [sube PDF]
‚Üí Frontend env√≠a: { input: "Resume este PDF", file: "base64...", mimeType: "application/pdf" }
‚Üí Backend extrae texto del PDF
‚Üí Backend env√≠a al modelo: "Resume este PDF\n\n--- Contenido: ---\n[texto extra√≠do]"
‚Üí Modelo analiza el texto y resume
‚Üí Modelo responde con resumen
```

### **Ejemplo 3: Ejecuci√≥n de Agente**
```
Usuario: "Ejecuta el agente de agenda del consejo"
‚Üí Modelo detecta solicitud de ejecuci√≥n
‚Üí Sistema llama: POST /api/agents/ceo-agenda-consejo/execute
‚Üí Backend ejecuta webhook de Make
‚Üí Backend retorna resultado
‚Üí Modelo presenta resultado al usuario
```

---

## ‚úÖ CONCLUSI√ìN

**TODAS las conexiones est√°n implementadas y listas para que el modelo las use**. El sistema est√° preparado para que el modelo de IA ejerza todas sus funciones:

- ‚úÖ Analizar im√°genes
- ‚úÖ Analizar archivos (PDF, DOC, TXT, CSV)
- ‚úÖ Ejecutar agentes automatizados (N8N/Make)
- ‚úÖ Consultar base de datos
- ‚úÖ Recibir webhooks del CRM

**El modelo puede usar cualquiera de estas conexiones cuando las necesite.**


